# ğŸ“‚ Sortify â€” AI-Powered File Organizer

**Sortify** is an AI-powered tool that helps you **summarize, categorize, and organize your PDF and text files** into folders using **LLMs**.

## </> Demo
```
# Unorganized files
~/sortify/files$ ls
Alice_in_Wonderland.pdf  Attention_Is_All_You_Need.pdf  Intro_To_RL.pdf  Segment_Anything.pdf

# Organizing files
~/sortify$ python main.py -cmd organize -dir ./files/ -cat "NLP, Computer_Vision, Reinforcement_Learning, Other"
Classification Results:
Segment_Anything.pdf: Computer_Vision
Intro_To_RL.pdf: Reinforcement_Learning
Attention_Is_All_You_Need.pdf: NLP
Alice_in_Wonderland.pdf: Other

# Organized directories
~/sortify/files$ ls
Computer_Vision  NLP  Other  Reinforcement_Learning

# Directory structure
~/sortify/files$ tree .
.
â”œâ”€â”€ Computer_Vision
â”‚Â Â  â””â”€â”€ Segment_Anything.pdf
â”œâ”€â”€ NLP
â”‚Â Â  â””â”€â”€ Attention_Is_All_You_Need.pdf
â”œâ”€â”€ Other
â”‚Â Â  â””â”€â”€ Alice_in_Wonderland.pdf
â””â”€â”€ Reinforcement_Learning
    â””â”€â”€ Intro_To_RL.pdf

5 directories, 4 files
```

---

## âœ¨ Features

* ğŸ“„ **Supports PDFs & TXT files** â€” automatic text extraction
* âœ‚ï¸ **Chunking** â€” splits large documents for efficient processing
* ğŸ“ **Summarization** â€” uses Hugging Face's summarization pipeline with `facebook/bart-large-cnn` to generate concise summaries for category generation.
* ğŸ§  **LLM-assisted categorization** â€” leverages summaries + **Groqâ€™s LLaMA models** to:

  * Suggest useful categories for your collection
  * Classify each document into the best matching category
* ğŸ“‚ **Smart file organization** â€” moves files into category-based folders automatically


---

## ğŸ” How It Works

1. Extracts text from `.pdf` and `.txt` files
2. Splits content into manageable chunks
3. Generates summaries with Hugging Faceâ€™s **BART** model
4. Uses summaries + **Groq LLaMA** for categorization
5. Moves files into their assigned category folders

---

## âš™ï¸ Installation

1. Clone the repo:

   ```bash
   git clone https://github.com/sajjadim/sortify.git
   cd sortify
   ```

2. Create a virtual environment & install dependencies:

   ```bash
   python -m venv venv
   source venv/bin/activate   # macOS/Linux  
   venv\Scripts\activate      # Windows  

   pip install -r requirements.txt
   ```

3. Add your **Groq API key** to a `.env` file:

   ```
   KEY=your_groq_api_key_here
   ```

---

## â–¶ï¸ Usage

### 1. Generate Suggested Categories

```bash
python main.py --command categories --directory ./papers/
```

### 2. Organize Papers Automatically

```bash
python main.py --command organize --directory ./papers/
```

### 3. Use Custom Categories

```bash
python main.py --command organize --directory ./papers/ --categories "AI, Healthcare, Finance"
```



## ğŸ“¦ Requirements

* Python 3.9+
* [PyMuPDF](https://pymupdf.readthedocs.io/) (`fitz`)
* [transformers](https://huggingface.co/transformers/)
* [datasets](https://huggingface.co/docs/datasets/)
* [groq](https://groq.com/) SDK
* `python-dotenv`

---

## âš ï¸ Limitations

* Summaries may miss nuances for very long documents
* Categorization depends on summary quality & LLaMA responses
* Requires **Groq API access**

Perfect ğŸ™Œ those are great roadmap items. Adding a **â€œFuture Workâ€** section in your README not only shows vision but also attracts contributors. Hereâ€™s how you can extend your README ğŸ‘‡

---

## ğŸš€ Future Work

* ğŸ¥ **Multimedia support**

  * Extract and analyze content from images, audio, and video files (e.g., OCR for images, speech-to-text for audio/video).

* ğŸ” **Global semantic search**

  * Build an embedding-based index across all files for powerful semantic search, making it easy to find concepts instead of just keywords.

* â“ **Question Answering (QA) over documents**

  * Ask natural language questions about your collection and receive grounded answers, powered by retrieval + LLMs.

